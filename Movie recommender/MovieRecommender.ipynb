{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Build a Movie recommender using 100k Dataset from 100 users on 1700 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wawins/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Necessary Imports for further use \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "1682\n"
     ]
    }
   ],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "#Reading data file u.data\n",
    "ratings = pd.read_csv('u.data', sep='\\t', names=r_cols,\n",
    " encoding='latin-1')\n",
    "\n",
    "\n",
    "num_users = ratings.user_id.unique().shape[0]\n",
    "num_items = ratings.movie_id.unique().shape[0]\n",
    "print(num_users) \n",
    "print(num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Ratings Data - 75%\n",
      "(75000, 4)\n",
      "       user_id  movie_id  rating  unix_timestamp\n",
      "88905      751        90       3       889298528\n",
      "58231      700       168       3       884494420\n",
      "74853      234       119       3       892335261\n",
      "9858       288       300       5       886372155\n",
      "17441      320       895       4       884748346\n",
      "Testing Ratings Data - 25%\n",
      "(25000, 4)\n",
      "       user_id  movie_id  rating  unix_timestamp\n",
      "94367      532       127       5       893119438\n",
      "32954      456      1324       4       881371720\n",
      "93323      912       418       4       875966694\n",
      "35574      474        87       4       887925916\n",
      "21770       65       365       3       879216672\n"
     ]
    }
   ],
   "source": [
    "#Spliting the data into training and testing\n",
    "training_ratings_data, testing_ratings_data = cv.train_test_split(ratings, test_size=0.25)\n",
    "\n",
    "print(\"Training Ratings Data - 75%\")\n",
    "print(training_ratings_data.shape)\n",
    "print(training_ratings_data.head())\n",
    "print(\"Testing Ratings Data - 25%\")\n",
    "print(testing_ratings_data.shape)\n",
    "print(testing_ratings_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Item Matrix\n",
      "[[ 0.  3.  4. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 5.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  5.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#Building a USer-Item Matrix\n",
    "\n",
    "training_ratings_matrix = np.zeros((num_users, num_items))\n",
    "\n",
    "for row in training_ratings_data.itertuples():\n",
    "    training_ratings_matrix[row[1]-1, row[2]-1] = row[3]\n",
    "\n",
    "testing_ratings_matrix = np.zeros((num_users, num_items))\n",
    "\n",
    "for row in testing_ratings_data.itertuples():\n",
    "    testing_ratings_matrix[row[1]-1, row[2]-1] = row[3]\n",
    "\n",
    "print(\"User-Item Matrix\")\n",
    "print(training_ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Similarity\n",
      "[[ 0.          0.90481063  0.97274101 ...,  0.88315881  0.84083529\n",
      "   0.70969974]\n",
      " [ 0.90481063  0.          0.90053396 ...,  0.89109211  0.85843482\n",
      "   0.901996  ]\n",
      " [ 0.97274101  0.90053396  0.         ...,  0.94670455  0.88065311  1.        ]\n",
      " ..., \n",
      " [ 0.88315881  0.89109211  0.94670455 ...,  0.          0.89789043\n",
      "   0.91957465]\n",
      " [ 0.84083529  0.85843482  0.88065311 ...,  0.89789043  0.          0.85609458]\n",
      " [ 0.70969974  0.901996    1.         ...,  0.91957465  0.85609458  0.        ]]\n",
      "Item Similarity\n",
      "[[ 0.          0.71131279  0.72435452 ...,  1.          0.94503503  1.        ]\n",
      " [ 0.71131279  0.          0.77943001 ...,  1.          0.90392311\n",
      "   0.90392311]\n",
      " [ 0.72435452  0.77943001  0.         ...,  1.          1.          0.88709351]\n",
      " ..., \n",
      " [ 1.          1.          1.         ...,  0.          1.          1.        ]\n",
      " [ 0.94503503  0.90392311  1.         ...,  1.          0.          1.        ]\n",
      " [ 1.          0.90392311  0.88709351 ...,  1.          1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Using Cosine similarity \n",
    "\n",
    "user_similarity = pairwise_distances(training_ratings_matrix, metric='cosine')\n",
    "item_similarity = pairwise_distances(training_ratings_matrix.T, metric='cosine')\n",
    "print(\"User Similarity\")\n",
    "print(user_similarity)\n",
    "print(\"Item Similarity\")\n",
    "print(item_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Prediction\n",
      "[[ 0.35499727  0.36317483  0.3746334  ...,  0.42115224  0.41374968\n",
      "   0.4057741 ]\n",
      " [ 0.07747142  0.08888193  0.08646652 ...,  0.09009255  0.09062327\n",
      "   0.09129991]\n",
      " [ 0.06336656  0.06516192  0.06364823 ...,  0.06021094  0.06450894\n",
      "   0.06510225]\n",
      " ..., \n",
      " [ 0.02399605  0.03187696  0.03097951 ...,  0.03581373  0.03493938\n",
      "   0.03558608]\n",
      " [ 0.13152535  0.14230441  0.1489871  ...,  0.1537318   0.15258944\n",
      "   0.15373413]\n",
      " [ 0.22018025  0.21674162  0.23927344 ...,  0.27650289  0.26735128\n",
      "   0.26670669]]\n",
      "Mean User Rating\n",
      "[ 0.41854935  0.09096314  0.06420927  0.04994055  0.22057075  0.34423306\n",
      "  0.71403092  0.09155767  0.04340071  0.35196195]\n",
      "User Prediction\n",
      "[[ 1.55463588  0.51576974  0.45205378 ...,  0.26857007  0.26877703\n",
      "   0.26823667]\n",
      " [ 1.27721783  0.23230337  0.1343431  ..., -0.07546768 -0.07434415\n",
      "  -0.07414556]\n",
      " [ 1.30867068  0.20405734  0.11136409 ..., -0.10521367 -0.103243\n",
      "  -0.10310411]\n",
      " ..., \n",
      " [ 1.15709858  0.16751898  0.07251936 ..., -0.1297104  -0.12886245\n",
      "  -0.12868419]\n",
      " [ 1.33452559  0.27955334  0.20507627 ..., -0.0046659  -0.00388601\n",
      "  -0.00368861]\n",
      " [ 1.39331253  0.35909077  0.30650978 ...,  0.12439233  0.12426901\n",
      "   0.12426399]]\n"
     ]
    }
   ],
   "source": [
    "item_prediction = training_ratings_matrix.dot(item_similarity) / np.array([np.abs(item_similarity).sum(axis=1)])\n",
    "print(\"Item Prediction\")\n",
    "print(item_prediction)\n",
    "mean_user_rating = training_ratings_matrix.mean(axis=1)\n",
    "print(\"Mean User Rating\")\n",
    "print(mean_user_rating[0:10])\n",
    "ratings_diff = (training_ratings_matrix - mean_user_rating[:, np.newaxis])\n",
    "user_prediction = mean_user_rating[:, np.newaxis] + user_similarity.dot(ratings_diff) / np.array([np.abs(user_similarity).sum(axis=1)]).T\n",
    "print(\"User Prediction\")\n",
    "print(user_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Ratings Prediction for Test Data Set\n",
      "[5, 2.0, 5, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 2.0]\n",
      "User Test Data Set\n",
      "[ 5.  3.  4.  1.  3.  5.  5.  5.  4.  2.]\n",
      "Item Ratings Prediction for Test Data Set\n",
      "[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "Item Test Data Set\n",
      "[ 5.  3.  4.  1.  3.  5.  5.  5.  4.  2.]\n"
     ]
    }
   ],
   "source": [
    "#Prediction for test dataset ans scaling user rating to five\n",
    "\n",
    "user_ratings_prediction = user_prediction[testing_ratings_matrix.nonzero()].flatten()\n",
    "ratings_five = [min(round(i*5), 5) for i in user_ratings_prediction]\n",
    "user_ratings_prediction = ratings_five\n",
    "user_testing_ratings_prediction = testing_ratings_matrix[testing_ratings_matrix.nonzero()].flatten()\n",
    "print(\"User Ratings Prediction for Test Data Set\")\n",
    "print(user_ratings_prediction[0:10])\n",
    "print(\"User Test Data Set\")\n",
    "print(user_testing_ratings_prediction[0:10])\n",
    "\n",
    "item_ratings_prediction = item_prediction[testing_ratings_matrix.nonzero()].flatten()\n",
    "ratings_five = [min(round(i*5), 5) for i in item_ratings_prediction]\n",
    "item_ratings_prediction = ratings_five\n",
    "item_testing_ratings_prediction = testing_ratings_matrix[testing_ratings_matrix.nonzero()].flatten()\n",
    "print(\"Item Ratings Prediction for Test Data Set\")\n",
    "print(item_ratings_prediction[0:10])\n",
    "print(\"Item Test Data Set\")\n",
    "print(item_testing_ratings_prediction[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE\n",
      "1.83518936353\n",
      "User-based CF RMSE\n",
      "2.67400822736\n"
     ]
    }
   ],
   "source": [
    "#Used Root Mean Squared Error(RMSE)\n",
    "\n",
    "user_prediction_error_eval = sqrt(mean_squared_error(user_ratings_prediction, user_testing_ratings_prediction))\n",
    "print('User-based CF RMSE')\n",
    "print(user_prediction_error_eval)\n",
    "item_prediction_error_eval = sqrt(mean_squared_error(item_ratings_prediction, item_testing_ratings_prediction))\n",
    "print('User-based CF RMSE')\n",
    "print(item_prediction_error_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity level of MovieLens100K is 93.7%\n"
     ]
    }
   ],
   "source": [
    "sparsity=round(1.0-len(ratings)/float(num_users*num_items),3)\n",
    "print('The sparsity level of MovieLens100K is ' +  str(sparsity*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
