{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Build a Movie recommender using 100k Dataset from 100 users on 1700 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wawins/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Necessary Imports for further use \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "1682\n"
     ]
    }
   ],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "#Reading data file u.data\n",
    "ratings = pd.read_csv('u.data', sep='\\t', names=r_cols,\n",
    " encoding='latin-1')\n",
    "\n",
    "\n",
    "num_users = ratings.user_id.unique().shape[0]\n",
    "num_items = ratings.movie_id.unique().shape[0]\n",
    "print(num_users) \n",
    "print(num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 943 users and 1632 movies in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Ratings Data - 75%\n",
      "(75000, 4)\n",
      "       user_id  movie_id  rating  unix_timestamp\n",
      "25674      468       258       4       875279126\n",
      "199        130       216       4       875216545\n",
      "12929       85        94       3       882995966\n",
      "45829      378       918       3       892383162\n",
      "19920      234       589       3       892078567\n",
      "Testing Ratings Data - 25%\n",
      "(25000, 4)\n",
      "       user_id  movie_id  rating  unix_timestamp\n",
      "7126       233       286       3       876690514\n",
      "74049      937       224       4       876769480\n",
      "64692      788        38       3       880871359\n",
      "33467      200       501       4       884129504\n",
      "65749      902       295       2       879465128\n"
     ]
    }
   ],
   "source": [
    "#Spliting the data into training and testing\n",
    "training_ratings_data, testing_ratings_data = cv.train_test_split(ratings, test_size=0.25)\n",
    "\n",
    "print(\"Training Ratings Data - 75%\")\n",
    "print(training_ratings_data.shape)\n",
    "print(training_ratings_data.head())\n",
    "print(\"Testing Ratings Data - 25%\")\n",
    "print(testing_ratings_data.shape)\n",
    "print(testing_ratings_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a User-Item Matrix\n",
    "\n",
    "\n",
    "The training set contains 943 users and 1682 movies. We are now creating the test_matrix and the train_matrix in which the number of rows is equal to the number of unique users and the number of columns is equal to the number of unique movies. The matrix cells are filled with the corresponding rating the user has given to the movie. The matrix cell has the value 0 if the user has not rated the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a USer-Item Matrix\n",
    "\n",
    "training_ratings_matrix = np.zeros((num_users, num_items))\n",
    "\n",
    "for row in training_ratings_data.itertuples():\n",
    "    training_ratings_matrix[row[1]-1, row[2]-1] = row[3]\n",
    "\n",
    "testing_ratings_matrix = np.zeros((num_users, num_items))\n",
    "\n",
    "for row in testing_ratings_data.itertuples():\n",
    "    testing_ratings_matrix[row[1]-1, row[2]-1] = row[3]\n",
    "\n",
    "#print(\"User-Item Matrix\")\n",
    "#print(training_ratings_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-Item based collabrative filter\n",
    "\n",
    "We create a similarity matrix which specifies the similarity between two users and items based on the ratings they have given to different movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Similarity\n",
      "(943, 943)\n",
      "[[ 0.          0.86008979  0.94443082 ...,  0.8719025   0.84370138\n",
      "   0.67046989]\n",
      " [ 0.86008979  0.          0.86751336 ...,  0.90024625  0.89801998\n",
      "   0.90851575]\n",
      " [ 0.94443082  0.86751336  0.         ...,  0.95111763  0.8321209\n",
      "   0.98524725]\n",
      " ..., \n",
      " [ 0.8719025   0.90024625  0.95111763 ...,  0.          0.9383455\n",
      "   0.92500046]\n",
      " [ 0.84370138  0.89801998  0.8321209  ...,  0.9383455   0.          0.83529012]\n",
      " [ 0.67046989  0.90851575  0.98524725 ...,  0.92500046  0.83529012  0.        ]]\n",
      "\n",
      "Item Similarity\n",
      "(1682, 1682)\n",
      "[[ 0.          0.68703644  0.75843361 ...,  1.          0.94550631  1.        ]\n",
      " [ 0.68703644  0.          0.79736039 ...,  1.          1.          0.90883943]\n",
      " [ 0.75843361  0.79736039  0.         ...,  1.          1.          1.        ]\n",
      " ..., \n",
      " [ 1.          1.          1.         ...,  0.          1.          1.        ]\n",
      " [ 0.94550631  1.          1.         ...,  1.          0.          1.        ]\n",
      " [ 1.          0.90883943  1.         ...,  1.          1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Using Cosine similarity \n",
    "\n",
    "user_similarity = pairwise_distances(training_ratings_matrix, metric='cosine')\n",
    "item_similarity = pairwise_distances(training_ratings_matrix.T, metric='cosine')\n",
    "print(\"User Similarity\")\n",
    "print(user_similarity.shape)\n",
    "print(user_similarity)\n",
    "print(\"\")\n",
    "print(\"Item Similarity\")\n",
    "print(item_similarity.shape)\n",
    "print(item_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The shape of similarity user-item matrix is 943 x 943 and 1682 x 1682 with each cell corresponding to the similarity between a user and item. Now we will use a prediction function that will predict the values in the user-item matrix. We will only consider the top n users which are similar to a user that are similar to a user to make predictions for that user. In the formula we normalise the ratings of users by subtracting the mean rating of a user from every rating given by the user. In the same way we will consider the item similarity and follow the above steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Prediction\n",
      "[[ 0.33250492  0.34864853  0.35860168 ...,  0.40333135  0.39885405\n",
      "   0.39582887]\n",
      " [ 0.08777485  0.09976398  0.09545823 ...,  0.10113028  0.10096916\n",
      "   0.10136909]\n",
      " [ 0.06527194  0.06835039  0.06639059 ...,  0.06781678  0.06843155\n",
      "   0.06879325]\n",
      " ..., \n",
      " [ 0.02820858  0.0350054   0.0347065  ...,  0.03985723  0.03932109\n",
      "   0.03909386]\n",
      " [ 0.13751286  0.14779831  0.15586676 ...,  0.16299822  0.16171268\n",
      "   0.16279745]\n",
      " [ 0.21833392  0.21747084  0.23164857 ...,  0.26710291  0.2605822\n",
      "   0.26061165]]\n",
      "Mean User Rating\n",
      "[ 0.40309156  0.10107015  0.06777646  0.04340071  0.22770511  0.33709869\n",
      "  0.70154578  0.10404281  0.03686088  0.35077289]\n",
      "User Prediction\n",
      "[[ 1.55008668  0.53270301  0.42686604 ...,  0.25030149  0.25293445\n",
      "   0.25287333]\n",
      " [ 1.33266229  0.27647717  0.13336343 ..., -0.06727641 -0.0640784\n",
      "  -0.06387835]\n",
      " [ 1.33869556  0.2402373   0.10545868 ..., -0.1023436  -0.09896578\n",
      "  -0.09885783]\n",
      " ..., \n",
      " [ 1.19672861  0.19944682  0.06936336 ..., -0.1265913  -0.12343978\n",
      "  -0.12349768]\n",
      " [ 1.38342554  0.31654653  0.2052507  ...,  0.00226323  0.00522373\n",
      "   0.00546945]\n",
      " [ 1.43019396  0.38908795  0.29048634 ...,  0.11430721  0.11671652\n",
      "   0.11685752]]\n"
     ]
    }
   ],
   "source": [
    "item_prediction = training_ratings_matrix.dot(item_similarity) / np.array([np.abs(item_similarity).sum(axis=1)])\n",
    "print(\"Item Prediction\")\n",
    "print(item_prediction)\n",
    "mean_user_rating = training_ratings_matrix.mean(axis=1)\n",
    "print(\"Mean User Rating\")\n",
    "print(mean_user_rating[0:10])\n",
    "ratings_diff = (training_ratings_matrix - mean_user_rating[:, np.newaxis])\n",
    "user_prediction = mean_user_rating[:, np.newaxis] + user_similarity.dot(ratings_diff) / np.array([np.abs(user_similarity).sum(axis=1)]).T\n",
    "print(\"User Prediction\")\n",
    "print(user_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Ratings Prediction for Test Data Set\n",
      "[2.0, 4.0, 4.0, 5, 2.0, 2.0, 4.0, 2.0, 2.0, 1.0]\n",
      "User Test Data Set\n",
      "[ 5.  2.  5.  5.  5.  4.  4.  3.  3.  2.]\n",
      "Item Ratings Prediction for Test Data Set\n",
      "[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "Item Test Data Set\n",
      "[ 5.  2.  5.  5.  5.  4.  4.  3.  3.  2.]\n"
     ]
    }
   ],
   "source": [
    "#Prediction for test dataset ans scaling user rating to five\n",
    "\n",
    "user_ratings_prediction = user_prediction[testing_ratings_matrix.nonzero()].flatten()\n",
    "ratings_five = [min(round(i*5), 5) for i in user_ratings_prediction]\n",
    "user_ratings_prediction = ratings_five\n",
    "user_testing_ratings_prediction = testing_ratings_matrix[testing_ratings_matrix.nonzero()].flatten()\n",
    "print(\"User Ratings Prediction for Test Data Set\")\n",
    "print(user_ratings_prediction[0:10])\n",
    "print(\"User Test Data Set\")\n",
    "print(user_testing_ratings_prediction[0:10])\n",
    "\n",
    "item_ratings_prediction = item_prediction[testing_ratings_matrix.nonzero()].flatten()\n",
    "ratings_five = [min(round(i*5), 5) for i in item_ratings_prediction]\n",
    "item_ratings_prediction = ratings_five\n",
    "item_testing_ratings_prediction = testing_ratings_matrix[testing_ratings_matrix.nonzero()].flatten()\n",
    "print(\"Item Ratings Prediction for Test Data Set\")\n",
    "print(item_ratings_prediction[0:10])\n",
    "print(\"Item Test Data Set\")\n",
    "print(item_testing_ratings_prediction[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root Mean Squared Error \n",
    "\n",
    "Using the root mean squared error to calculate the accuracy of the predicted ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE\n",
      "1.83198253267\n",
      "Item-based CF RMSE\n",
      "2.68016417408\n"
     ]
    }
   ],
   "source": [
    "#Used Root Mean Squared Error(RMSE)\n",
    "\n",
    "user_prediction_error_eval = sqrt(mean_squared_error(user_ratings_prediction, user_testing_ratings_prediction))\n",
    "print('User-based CF RMSE')\n",
    "print(user_prediction_error_eval)\n",
    "item_prediction_error_eval = sqrt(mean_squared_error(item_ratings_prediction, item_testing_ratings_prediction))\n",
    "print('Item-based CF RMSE')\n",
    "print(item_prediction_error_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity level of MovieLens100K is 93.7%\n"
     ]
    }
   ],
   "source": [
    "sparsity=round(1.0-len(ratings)/float(num_users*num_items),3)\n",
    "print('The sparsity level of MovieLens100K is ' +  str(sparsity*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Getting recommendation for the user\n",
    "\n",
    "getting movie recommendation for the user with user_id 25 user-item collaborative filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    3, ..., 1679, 1680, 1681])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 25\n",
    "user_ratings_prediction = item_prediction[user_id-1,:]\n",
    "train_unkown_indices = np.where(training_ratings_matrix[user_id-1,:] == 0)[0]\n",
    "train_unkown_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Recommendation for the user 25 are the movies:\n",
      "\n",
      "1325\n",
      "1322\n",
      "1195\n",
      "1308\n",
      "1528\n"
     ]
    }
   ],
   "source": [
    "user_recommendations = user_ratings_prediction[train_unkown_indices]\n",
    "print('\\n Recommendation for the user {} are the movies:\\n'.format(user_id))\n",
    "for movie_id in user_recommendations.argsort()[-5:][: : -1]:\n",
    "    print(movie_id +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular value Decomposition\n",
    "\n",
    "SVD is a model-based method. It is a mathematical technique to find the missing values in a matrix. It decomposes matrix into three matrices two of which are rectangular and the middle one is a diagonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((943, 20), (20,), (20, 1682))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "import math\n",
    "from scipy.sparse.linalg import svds\n",
    "u, s, vt = svds(training_ratings_matrix, k = 20)\n",
    "u.shape, s.shape, vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_diag_matrix = np.diag(s)\n",
    "predictions_svd = np.dot(np.dot(u,s_diag_matrix),vt)\n",
    "predictions_svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7175485558019754"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings_svd = predictions_svd[testing_ratings_matrix.nonzero()]\n",
    "test_truth = testing_ratings_matrix[testing_ratings_matrix.nonzero()]\n",
    "math.sqrt(mean_squared_error(predicted_ratings_svd,test_truth))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE for the SVD is calculated and further on we find the recommendation for the user with ID 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1620,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 25\n",
    "user_ratings = predictions_svd[user_id-1,:]\n",
    "train_unkown_indices = np.where(training_ratings_matrix[user_id-1,:] == 0)[0]\n",
    "user_recommendations = user_ratings[train_unkown_indices]\n",
    "user_recommendations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for user 25 are the movies: \n",
      "\n",
      "91\n",
      "44\n",
      "149\n",
      "168\n",
      "549\n"
     ]
    }
   ],
   "source": [
    "print('\\nRecommendations for user {} are the movies: \\n'.format(user_id))\n",
    "for movie_id in user_recommendations.argsort()[-5:][: : -1]:\n",
    "    print(movie_id +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
